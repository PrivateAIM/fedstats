import numpy as np
from flame.star import StarModel, StarAnalyzer, StarAggregator
from fedstats import FederatedGLM, PartialFisherScoring
from fedstats.util import simulate_logistic_regression


class LocalFisherScoring(StarAnalyzer):
    def __init__(self, flame):
        """
        Initializes local analyzer node
        """
        super().__init__(flame)  # Connects this analyzer to the FLAME components
        self.iteration = 0
        local_PRNGKey = np.random.randint(1, 99999)
        X, y = simulate_logistic_regression(
            local_PRNGKey, n=50, k=1
        )  # k=1 as we need only one dataset
        self.X, self.y = X[0], y[0]

        self.local_model_parts = PartialFisherScoring(
            self.X, self.y, family="binomial", fit_intercept=False
        )
        print(f"Initial values of beta: {self.local_model_parts.beta}")

    def analysis_method(self, data, aggregator_results):
        """
        Runs local parts of the federated fisher scoring
        Fits score vectore and fisher information matrix on current values from aggregator results
        aggregator_results should be a list with one element. This element is a tuple 2 elements:
        1. Aggregation results (np.ndarray) 2. convergence flag
        """
        # first iteration, aggregator gives no results and therefore None, use local inital values
        if self.iteration == 0:
            # wrap as a list (reason in next line)
            aggregator_results = [(self.local_model_parts.beta, False)]

        # aggregator_results are a list with one element
        aggregator_results = aggregator_results[0]

        # if condition checks, converged flag. In the case of convergence, return the result
        if not aggregator_results[1]:
            aggregator_results = aggregator_results[0]
            self.iteration += 1
            print(f"Aggregator results are: {aggregator_results}")
            self.local_model_parts.set_coefs(aggregator_results)
            return self.local_model_parts.calc_fisher_scoring_parts(verbose=True)
        else:
            return aggregator_results[0]


class FederatedLogisticRegression(StarAggregator):
    def __init__(self, flame):
        """
        Initializes aggregator object and iteratively checks for convergence
        and aggegates fisher scoring parts from each node
        """
        super().__init__(flame)  # Connects this aggregator to the FLAME components
        self.glm = FederatedGLM()

        # additional tmp flag to keep track of convergence *independent* of convergence in has_converged() to modify final result
        self._convergence_flag = False

    def aggregation_method(self, analysis_results):
        """
        Aggregates the results received from all analyzer nodes.

        :param analysis_results: A list of analysis results from each analyzer node.
        :return: The aggregated result (e.g., total patient count across all analyzers).
        """
        if not self._convergence_flag:
            self.glm.set_results(analysis_results)
            self.glm.aggregate_results()
            return self.glm.get_coefs(), self._convergence_flag
        else:
            return self.glm.get_summary()

    def has_converged(self, result, last_result, num_iterations):
        """
        Determines if the aggregation process has converged.

        :param result: The current aggregated result.
        :param last_result: The aggregated result from the previous iteration.
        :param num_iterations: The number of iterations completed so far.
        :return: True if the aggregation has converged; False to continue iterations.
        """
        if self._convergence_flag:
            print(f"Converged after {num_iterations} iterations.")
            return True

        convergence = self.glm.check_convergence(last_result[0], result[0], tol=1e-4)
        if convergence:
            # TODO: Currently, a the following is a workaround. Another round of analysis is done with no results such that
            # the final result can be modified. Maybe there is a better solution in the future.
            self._convergence_flag = True
            return False  # here, False is returned even though convergence is achieved to perform a final "redundant" round
        elif num_iterations > 100:
            # TODO: Include option for max iteration and not hardcoded tol
            print(
                "Maximum number of 100 iterations reached. Returning current results."
            )
            return True
        else:
            return False


def main():
    """
    Sets up and initiates the distributed analysis using the FLAME components.

    - Defines the custom analyzer and aggregator classes.
    - Specifies the type of data and queries to execute.
    - Configures analysis parameters like iteration behavior and output format.
    """
    StarModel(
        analyzer=LocalFisherScoring,  # Custom analyzer class (must inherit from StarAnalyzer)
        aggregator=FederatedLogisticRegression,  # Custom aggregator class (must inherit from StarAggregator)
        data_type="s3",  # Type of data source ('fhir' or 's3')
        # query="Patient?_summary=count",  # Query or list of queries to retrieve data
        simple_analysis=False,  # True for single-iteration; False for multi-iterative analysis
        output_type="str",  # Output format for the final result ('str', 'bytes', or 'pickle')
        analyzer_kwargs=None,  # Additional keyword arguments for the custom analyzer constructor (i.e. MyAnalyzer)
        aggregator_kwargs=None,  # Additional keyword arguments for the custom aggregator constructor (i.e. MyAggregator)
    )


if __name__ == "__main__":
    main()
